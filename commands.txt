data_cleaning
data
Data I/O
Read and write .csv
import delimited using "https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv", clear \nexport delimited using "flightdata.csv", replace
dat = fread('https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv')\nfwrite(dat, 'flightdata.csv')

data_cleaning
data
Data I/O
Read and write .dta
* .dta is Stata's native (proprietary) filetype \nuse "filename.dta", clear \n\n\nsave "filename.dta", replace
# These commands require the `haven` package \ndat = haven::read_dta('filename.dta') \nsetDT(dat) # Or: dat = as.data.table(dat) \n \nhaven::write_dta(dat, 'filename.dta')

data_cleaning
sort
Sort & rename
Sort rows
sort air_time \nsort air_time dest \ngsort -air_time\n\n
setorder(dat, air_time) \nsetorder(dat, air_time, dest) \nsetorder(dat, -air_time)

data_cleaning
sort
Sort & rename
Sort columns
order month day
setcolorder(dat, c('month','day'))

data_cleaning
sort
Sort & rename
Rename columns
* rename (old) (new) \n\nrename arr_delay arrival_delay \nrename (carrier origin) (carrier_code origin_code) \nrename arr_* arrival_*
# setnames(dat, old = ..., new = ...) \n\nsetnames(dat, 'arr_delay', 'arrival_delay') \nsetnames(dat, c('carrier','origin'), c('carrier_code','origin_code')) \nsetnames(dat, gsub('arr_', 'arrival_', names(dat)))

data_cleaning
subset
Subset
Subset rows
* Reminder: You'll need to use preserve/restore\n* if you want to retain the original dataset in \n* the examples that follow. \n\nkeep in 1/200 \nkeep if day > 5 & day < 10\nkeep if inrange(day,5,10)\nkeep if origin == "LGA"\nkeep if regex(origin,"LGA") \nkeep if inlist(month,3,4,11,12) \nkeep if inlist(origin,"JFK","LGA") \ndrop if month == 1
# Reminder: You'll need to (re)assign the \n# collapsed dataset if you want to use it later,\n# e.g. dat1 = dat[1:200] \n\ndat[1:200] \ndat[day > 5 & day < 10] \ndat[between(day,5,10)] # Or: dat[day %in% 5:10] \ndat[origin=='LGA']\ndat[origin %like% 'LGA'] \ndat[month %in% c(3,4,11,12)] \ndat[origin %chin% c("JFK","LGA")] # %chin% is a faster %in% for (ch)aracter strings \ndat[month!=1]

data_cleaning
subset
Subset
Subset columns
* Reminder: You'll need to use preserve/restore\n* if you want to retain the original dataset in \n* the examples that follow. \n\nkeep month day carrier \n\n\n\nkeep year-arr_delay\nkeep *_delay \n\nds, has(type int) \nkeep `r(varlist)'\n\ndrop origin dest \n\n\nds, has(type string) \ndrop `r(varlist)'
# Reminder: You'll need to (re)assign the \n# collapsed dataset if you want to use it later,\n# e.g. dat1 = dat[, .(month, day, carrier)] \n\ndat[, .(month, day, carrier)] \ndat[, list(month, day, carrier)] # same as above \ndat[, c('month', 'day', 'carrier')] # ditto \n\ndat[, year:arr_delay] \ndat[, .SD, .SDcols=patterns('*_delay')] \n\n# Matches the two lines on the left: \ndat[, .SD, .SDcols=is.integer] \n\ndat[, -c('origin', 'dest')]\ndat[, c('origin', 'dest') := NULL] # same, but drops columns in-place \n\n# Matches the two lines on the left:\ndat[, .SD, .SDcols=!is.character]

data_cleaning
subset
Subset
Subset rows and columns
* Reminder: You'll need to use preserve/restore\n* if you want to retain the original dataset in \n* the examples that follow. \n\nkeep if origin == "LGA"\nkeep month day carrier
# Reminder: You'll need to (re)assign the \n# collapsed dataset if you want to use it later,\n# e.g. dat1 = dat[origin=="LGA", .(month, day, carrier)] \n\n# Matches the two lines on the left:\ndat[origin=="LGA", .(month, day, carrier)]

data_cleaning
subset
Subset
Drop duplicates
* Reminder: You'll need to use preserve/restore\n* if you want to retain the original dataset in \n* the examples that follow. \n\nduplicates drop\nduplicates drop month day carrier, force\n
# Reminder: You'll need to (re)assign the \n# collapsed dataset if you want to use it later,\n# e.g. dat1 = unique(dat) \n\nunique(dat) \nunique(dat, by = c('month', 'day', 'carrier'))

data_cleaning
subset
Subset
Drop missing
* Reminder: You'll need to use preserve/restore\n* if you want to retain the original dataset in \n* the examples that follow. \n\nkeep if !missing(dest)\n* Requires: ssc inst missings\nmissings dropvars, force \nmissings air_time dest, force \n
# Reminder: You'll need to (re)assign the \n# collapsed dataset if you want to use it later,\n# e.g. dat = dat[!is.na(dest)] \n\ndat[!is.na(dest)]\n\nna.omit(dat) \nna.omit(dat, cols = c('air_time', 'dest')) \ndat[!is.na(air_time) & !is.na(dest)] # Same as above

data_cleaning
modify
Modify
Create new variables
gen dist_sq = distance^2 \ngen tot_delay = dep_delay + arr_delay \ngen first_letter = substr(origin, 1,1) \ngen flight_path = origin + '_' + dest \n\n* These next operations don't have a great Stata \n* equivalent, although you could implement a loop.
dat[, dist_sq := distance^2] \ndat[, tot_delay := dep_delay + arr_delay] \ndat[, first_letter := substr(origin,1,1)] \ndat[, flight_path := paste(origin, dest, sep='_')] \n\n# Multiple variables can be created at once.\n# These next few lines all do the same thing.\n# Just pick your favourite. \ndat[, c('dist_sq', 'dist_cu') := .(distance^2, distance^3)] \ndat[, ':=' (dist_sq=distance^2, dist_cu=distance^3)] # "functional" equivalent \ndat[, let(dist_sq=distance^2, dist_cu=distance^3)] # requires dev version of data.table\n\n# We can also chain back-to-back dat[...][...] \n# (this holds for any data.table operation) \ndat[, dist_sq := distance^2][, dist_cu := distance*dist_sq)]

data_cleaning
modify
Modify
Create new variables within groups
bysort origin: egen mean_dep_delay = mean(dep_delay) \nbysort origin dest: egen mean_dep_delay2 = mean(dep_delay) \n\n* Multiple grouped variables (manual demean example) \nforeach x of varlist dep_delay arr_delay air_time {\n    egen mean_`x'=mean(`x'), by(origin) \n    gen `x'_dm = `x` - mean_`x' \n    drop mean* \n}\n\n* Some short-cut symbols \nbysort carrier: g rows_per_carrier = _N \nbysort carrier: g index_within_carrier = _n \negen origin_index = group(origin)\n\n* Refer to other rows (uses generic data set)\nsort group time\nby group: gen growth = X/X[_n-1]\nby group: gen growth_since_first = X/X[1]
dat[, mean_dep_delay := mean(dep_delay), by=origin] \ndat[, mean_dep_delay2 := mean(dep_delay), by=.(origin, dest)] \n\n# Multiple grouped variables (manual demean example) \ndmcols = c('dep_delay', 'arr_delay', 'air_time') \ndat[,\n    paste0(dmcols,'_dm') := lapply(.SD, \(x) x-mean(x)),  # before R 4.1 you'll need function(x) instead of the \(x) shorthand\n    .SDcols = dmcols,\n    by = origin] \n\n# Some short-cut symbols \ndat[, rows_per_carrier := .N, by = carrier] \ndat[, index_within_carrier := .I, by = carrier] \ndat[, origin_index := .GRP, by = origin]\n\n# Refer to other rows (uses generic data set)\nsetorder(dat, group, time)\ndat[, growth := X/shift(X, 1), by = group]\ndat[, growth_since_first := X/first(X), by = group]

data_cleaning
modify
Modify
Work With Dates
* Give ourselves a date variable to work with\ntostring year month day, replace\ngen day_string = year + "/" + month + "/" + day\ngen date = date(day_string, "YMD")\nformat date %td\n\n* Pull out year (quarter, month, etc. work too)\ngen the_year = year(date)\n\n* Shift forward 7 days\nreplace date = date + 7
# Make ourselves a date variable\ndat[, day_string := paste(year, month, day, sep = '/')]\ndat[, date := as.IDate(day_string)]\n\n\n\n# Pull out year (quarter, month, etc. work too)\ndat[, the_year := year(date)]\n\n# Shift forward 7 days\ndat[, date := date + 7]


data_cleaning
modify
Modify
Modify existing variables
replace tot_delay = dep_delay + arr_delay \n\n* Conditional modification \nreplace distance = distance + 1 if month==9\nreplace distance = 0 in 1 \n\n* Modify multiple variables (same function) \nforeach x of varlist origin dest {\n    replace `x' = `x' + " Airport"\n}
dat[, tot_delay := dep_delay + arr_delay] \n\n# Conditional modification \ndat[month==9, distance := distance + 1]\ndat[1, distance := 0]\n\n# Modify multiple variables (same function) \ncols = c('origin','dest')\ndat[, (cols) := lapply(.SD, \(x) paste(x,'Airport')),  ## Note: before R 4.1 you need function(x) instead of the \(x) shorthand \n    .SDcols = cols] \n\n# Aside: We don't normally use a gen -> replace \n# workflow in R, the way we do in Stata. See the \n# 'Using Booleans & control-flow' section below.

data_cleaning
modify
Modify
Using Booleans & control-flow
gen long_flight = air_time>500 & !missing(air_time) \n\ngen flight_length = "Long" if air_time>500 & !missing(air_time)\nreplace flight_length = "Short" if missing(flight_length) & !missing(air_time) \n\n\ngen flight_length2 = "Long" if !missing(air_time) \nreplace flight_length2 = "Med" if air_time<=500  \nreplace flight_length2 = "Short" if air_time<=120
dat[, long_flight := air_time>500] \n\ndat[, flight_length := fifelse(air_time>500, 'Long', 'Short')] \n# fifelse is like base-R ifelse, but (f)aster! \n\n# for nested ifelse, easier to use fcase \ndat[, flight_length2 := fcase(air_time<=120, 'Short', \n                              air_time<=500, 'Med', \n                              default = 'Long')]

data_cleaning
modify
Modify
Row-wise calculations
* Pre-packaged row calculations: \negen tot_delay = rowtotal(*_delay)\negen any_delay = rowfirst(*_delay)\n\n* Custom row calculations:\n* ?
# Pre-packaged row calculations: \ndat[, tot_delay := rowSums(.SD), .SDcols = patterns('*_delay')]\ndat[, any_delay := fcoalesce(.SD), .SDcols = patterns('*_delay')] \n\n# Custom row calculations: \ndat[, new_var := mapply(custom_func, var1, var2)] \ndat[, new_var := custom_func(var1, var2)), by=1:nrow(dat)] # Another option\n\n

data_cleaning
modify
Modify
Fill in Time Series/Panel Data
* Carry forward the last-known observation\nsort id time\nby id: replace x = x[_n-1] if missing(x)\n* Carry back the next-known observation\ngsort id -time\nby id: replace x = x[_n-1] if missing(x)
# Carry forward the last-known observation\nsetorder(dat, id, time)\ndat[, x := nafill(x, type = 'locf'), by = id]\n# Carry back the next-known observation\ndat[, x := nafill(x, type = 'nocb'), by = id]

data_cleaning
collapse
Collapse
Collapse with no grouping
* Reminder: You'll need to use preserve/restore\n* if you want to retain the original dataset in \n* the examples that follow. \n\ncollapse (mean) dep_delay \ncollapse (mean) mean_ddel=dep_delay \n\ncollapse (mean) mean_ddel=dep_delay mean_adel=arr_delay \n\n\n\ncollapse (mean) *delay \n\nds, has(type long)\ncollapse (mean) `r(varlist)'
# Reminder: You'll need to (re)assign the \n# collapsed dataset if you want to use it later,\n# e.g. dat1 = dat[, mean(dep_delay)] \n\ndat[, mean(dep_delay)] # Just give me the number! As a scalar. \ndat[, .(mean_ddel=mean(dep_delay))] # Give me back a data.table (note the .() here, that's what does it) \n\ndat[, .(mean_ddel=mean(dep_delay), mean_adel=mean(arr_delay))]\ndat[, lapply(.SD, mean), .SDcols=c('arr_delay','dep_delay')] # same \ndat[, lapply(.SD, mean), .SDcols=arr_delay:dep_delay] # ditto \n\ndat[, lapply(.SD, mean), .SDcols=patterns('delay')] \n\n # Matches the two lines on the left\ndat[, lapply(.SD, mean), .SDcols=is.numeric]

data_cleaning
collapse
Collapse
Collapse by group
* Reminder: You'll need to use preserve/restore\n* if you want to retain the original dataset in \n* the examples that follow. \n\ncollapse (mean) arr_delay, by(carrier) \ncollapse (mean) mean_adel = arr_delay, by(carrier) \n\ncollapse (mean) arr_delay, by(carrier month) \n\ncollapse (min) min_d = distance (max) max_d = distance, by(origin) \n\ncollapse (mean) *_delay, by(origin) \ncollapse (mean) dep_delay arr_delay air_time distance, by(origin) \n\n\negen unique_dest = tag(dest origin) \ncollapse (sum) unique_dest, by(origin)
# Reminder: You'll need to (re)assign the \n# collapsed dataset if you want to use it later,\n# e.g. dat1 = dat[, mean(dep_delay), by=origin] \n\ndat[, .(arr_delay = mean(arr_delay)), by=carrier] \ndat[, .(mean_adel = mean(arr_delay)), by=carrier] \n\ndat[, .(arr_delay = mean(arr_delay)), by=.(carrier, month)] \n\ndat[, .(min_d = min(distance), max_d = max(distance)), by=origin] \n\ndat[, lapply(.SD, mean), .SDcols=patterns('_delay'), by=origin] \ndat[, lapply(.SD, mean), .SDcols=c('dep_delay','arr_delay','air_time','distance'), by=origin] \ndat[, lapply(.SD, mean), .SDcols = c(4,5,9,10), by=origin] # same as above \n\n# Matches the final two lines on the left: \ndat[, .(unique_dest = uniqueN(dest)), by = origin] \n\n# Bonus: You can also do complicated (grouped)\n# aggregations as part of a dcast (i.e. reshape \n# wide) call. E.g. Get the min, mean and max\n# arrival and departure delays, by origin airport.\ndcast(dat, origin~., fun=list(min,mean,max),\n      value.var=c('arr_delay','dep_delay'))

data_cleaning
collapse
Collapse
Count rows
count\ncount if month==10\n* Count rows by group:\ntabulate origin
dat[, .N] # Or: nrow(dat) \ndat[month==10, .N] # Or: nrow(dat[month==10]\n# Count rows by group:\ndat[, .N, by = origin])

data_cleaning
reshape
Reshape
Reshape long
* Prepare to reshape long (this dataset only):\ngen id = _n \nrename (dep_delay arr_delay) (delay_dep delay_arr)\n\nreshape long delay_, i(id) j(delay_type) s
# Prepare to reshape long (this dataset only):\ndat[, id := .I] \n\ndat1 = melt(dat, measure.vars = c('arr_delay','dep_delay'))\n# note id.vars would normally be specified too, but here we're treating each row as its own ID

data_cleaning
reshape
Reshape
Reshape wide
* This starts with the reshaped-long data from above\nreshape wide delay_, (id) j(delay_type) s
# This starts with the reshaped-long data from above\ndat2 = dcast(dat1, id ~ variable)\n# (this drops all variables except id & *_delay, \n# but we could preserve them with id+origin+dest+etc. instead of just id)

data_cleaning
merge
Combining Data Sets
Import secondary (airport) dataset
import delimited using "https://vincentarelbundock.github.io/Rdatasets/csv/nycflights13/airports.csv", clear\nsave dat2.dta, replace\nimport delimited using "https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv", clear
dat2 = fread("https://vincentarelbundock.github.io/Rdatasets/csv/nycflights13/airports.csv")

data_cleaning
merge
Combining Data Sets
Various Merges
rename dest faa\n* Only keep matches (inner join)\nmerge m:1 faa using dat2.dta, keep(3) nogen\n* Keep all observations (full join)\nmerge m:1 faa using dat2.dta, nogen\n* Keep matches and "master" non-matches (left join)\nmerge m:1 faa using dat2.dta, keep(1 3) nogen\n* Keep matches and "using" non-matches (right join)\nmerge m:1 faa using dat2.dta, keep(2 3) nogen\n\nmerge m:1 faa using dat2.dta, keepusing(lat lon)\n\n\n\n\n\n\n\n\n\n\n\n\n* Keep only non-matches (anti-join)\nmerge m:1 faa using dat2.dta, keep(1 2) nogen
setnames(dat, 'dest', 'faa')\n# Only keep matches (inner join)\ndat_merged = merge(dat, dat2, by='dest')\n# Keep all observations (full join)\ndat_merged = merge(dat, dat2, by='dest', all = TRUE)\n# Keep matches and "master" non-matches (left join)\ndat_merged = merge(dat, dat2, by='dest', all.x = TRUE)\n# Keep matches and "using" non-matches (right join)\ndat_merged = merge(dat, dat2, by='dest', all.y = TRUE)\n\ndat_merged = merge(dat, dat2[, .(dest, lat, lon)], by='dest', all = TRUE)\n\n# Alternate merging approaches\n# Skip the setnames() and just merge with different variable names\ndat_merged = merge(dat, dat2, by.x='dest', by.y='faa') \n\n# If using keys, don't need 'by'/'on' (and faster) \nsetkey(dat, dest); setkey(dat2, dest) \ndat_merged = merge(dat, dat2)\n\n# Alternate, more data-tably syntax\n# That is also faster for some applications\ndat_merged = dat[dat2, on='dest']\n# Keep only non-matches (anti-join)\ndat_merged = dat[!dat2, on='dest']

data_cleaning
merge
Combining Data Sets
Appending Data
* This just appends the flights data to itself\nsave data_to_append.dta, replace\nappend using data_to_append.dta
# This just appends the flights data to itself\nrbindlist(list(dat, dat)) # Or rbind(dat, dat)\n# The fill = TRUE option is handy if the one data set has columns the other doesn't


regression
formula
Formula Creation
Fixed Effects
reghdfe wage educ i.fe\nreghdfe wage educ, absorb(fe)
feols(wage ~ educ + factor(countyfips), data = dat)\nfeols(wage ~ educ | countyfips, dat)

regression
formula
Formula Creation
Categorical Variables
reghdfe wage educ i.treat\n* Specifying a baseline:\nreghdfe wage educ ib1.treat
feols(wage ~ educ + factor(treat), dat)\n# Specifying a baseline:\nfeols(wage ~ educ + i(treat, ref = 1), dat)

regression
formula
Formula Creation
Interact Categoricals
\n\nreghdfe wage educ i.treat#i.hisp
feols(wage ~ educ + treat*hisp, data = dat) # base-R approach\n# Approach specific to fixest that makes iplot() work later if desired:\nfeols(wage ~ educ + i(treat, i.hisp), dat)

regression
formula
Formula Creation
Interact Categorical and Continuous
\nreghdfe wage educ c.age#i.treat
feols(wage ~ educt + treat*age, data = dat) # base-R approach\n# Approach specific to fixest that makes iplot() work later if desired:\nfeols(wage ~ educ + i(treat, age), dat)

regression
formula
Formula Creation
Macros
local vars age black hisp marr \n reghdfe wage educ `vars'
vars = c("age", "black", "hisp", "marr") \n feols(wage ~ educ + .[vars], dat)

regression
formula
Formula Creation
Wildcard
reghdfe wage educ x*
feols(wage ~ educ + ..('x'), dat)

regression
formula
Formula Creation
Variables x1 ... x4
reghdfe wage educ x1-x4
feols(wage ~ educ + x.[1:4], dat)

regression
formula
Formula Creation
Regex
 
feols(wage ~ educ + ..('regex_exp'), dat)

regression
std_errors
Standard Errors
HC
reghdfe wage educ, vce(hc1)
feols(wage ~ educ, dat, vcov = 'hc1')

regression
std_errors
Standard Errors
HAC
xtset id year\nivreghdfe wage educ, bw(auto) robust
feols(wage ~ educ, dat, vcov = NW() ~ id + year)\nfeols(wage ~ educ, dat, vcov = 'NW') # if panel id is already set (see below)

regression
std_errors
Standard Errors
Cluster
reghdfe wage educ, cluster(countyfips)
feols(wage ~ educ, dat, vcov = ~countyfips)

regression
std_errors
Standard Errors
Two-way
reghdfe wage educ, cluster(countyfips year)
feols(wage ~ educ, dat, vcov = ~countyfips + year)

regression
std_errors
Standard Errors
Conley Standard Errors
* Figuring this out: http://www.trfetzer.com/conley-spatial-hac-errors-with-fixed-effects/
feols(wage ~ educ, dat, vcov = conley("25 mi"))

regression
post
Postestimation

regression Table
reghdfe wage educ age black hisp marr \n eststore est1 \n esttab est1\n\nreghdfe wage educ age black hisp\neststore est2\nesttab est1 est2
est1 = feols(wage ~ educ + age + black + hisp + marr, dat) \n etable(est1)\n\n\nest2 = feols(wage ~ educ + age + black + hisp, dat) \netable(est1,est2)

regression
post
Postestimation
Coefficient Plot
reghdfe wage educ age black hisp marr  \n eststore est1 \n coefplot ...
est1 = feols(wage ~ educ + age + black + hisp + marr, dat) \n coefplot(est1)

regression
panel
Panel Data
Lag Variables
xtset id year \n reg wage educ l1.wage
feols(wage ~ educ + l(wage, 1), dat, panel.id = ~id+year)

regression
panel
Panel Data
Lead Variables
xtset id year \n reg wage educ f1.wage
feols(wage ~ educ + l(wage, -1), dat, panel.id = ~id+year)

regression
panel
Panel Data
First Difference
xtset id year \n reg wage educ D.x
feols(wage ~ educ + d(wage), dat, panel.id = ~id+year)

regression
iv
Instrumental Variables
Instrumental Variables
ivreghdfe 2sls wage (educ = age)
feols(wage ~ 1 | educ ~ age, dat)

regression
iv
Instrumental Variables
with Fixed Effects
ivreghdfe 2sls wage (educ = age), absorb(countyfips)
feols(wage ~ 1 | countyfips | educ ~ age, dat)

misc
ggplot
Graphing with ggplot2
Basic Scatterplot
twoway scatter yvar xvar
ggplot(dat, aes(x = xvar, y = yvar)) + geom_point()

misc
tidyverse
The Tidyverse
Manipulating Dates with Lubridate
* Shift a date forward one month (not 30 days, one month)\n* ??? 
# Shift a date forward one month (not 30 days, one month)\nshifted_date = date + months(1)

misc
tidyverse
The Tidyverse
Iterating with purrr
* Read in many files and append them together\nlocal filelist: dir "Data/" files "*.dta"\nlocal firsttime = 1\nforeach f in filelist {\n    use `f', clear\n    if `firsttime' == 0 {\n        append using compiled_data.dta\n    }\n    save compiled_data.dta, replace\n}
# Read in many files and append them together\n# (this combines purrr with the data.table function fread)\nfilelist = list.files('Data/', pattern = '.csv')\ndat = filelist %>%\n    map_df(fread)

misc
tidyverse
The Tidyverse
String Functions with stringr
subinstr(string, "remove", "replace", .)\nsubstr(string, start, length)\nregex(string, "regex")
str_replace_all(string, "remove", "replace")\nstr_sub(string, start, end)\nstr_detect(string, "regex")\n# Note all the stringr functions accept regex input

misc
car
car and nlWaldTest for Coefficient Combinations
Basic combinations
regress y x z\nlincom x + z\nnlcom _b[x]/_b[z]
m = feols(y ~ x + z, data = dat)\nlinearHypothesis(m, 'x + z')\nnlWaldtest(m, 'b[2]/b[3]') # or nlConfint() instead for the confidence interval